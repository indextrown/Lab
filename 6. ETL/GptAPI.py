import os
import re
import json
import time
import requests
from dotenv import load_dotenv
from datetime import datetime
from urllib.parse import urlparse
from dataclasses import dataclass
from typing import List, Optional

# ==============================
# ğŸ“Š ì¹´í…Œê³ ë¦¬ ë§¤í•‘
# ==============================
CATEGORY_MAP = {
    "ê¸°íƒ€": 99,
    "íŒ¨ì…˜": 1,
    "ë·°í‹°": 2,
    "ë””ì €íŠ¸": 3,
    "ì¹´í˜": 4,
    "ì£¼ë¥˜": 5,
    "IT": 6,
    "ìƒí™œìš©í’ˆ": 7,
    "ìŠ¤í¬ì¸ ": 8,
    "ì˜í™”": 9,
    "ì• ë‹ˆë©”ì´ì…˜": 10,
    "ì›¹íˆ°": 11,
    "ì—°ì˜ˆì¸": 12,
    "ë¬¸í™”/ì˜ˆìˆ ": 13,
    "ì—¬í–‰": 14,
    "ë°˜ë ¤ë™ë¬¼": 15,
    "ê²Œì„": 16,
    "ì±…": 17,
    "ê¸ˆìœµ": 18,
    "ì¹œí™˜ê²½": 19,
    "í‚¤ì¦ˆ": 20
}

def convert_recommend_to_ids(recommend_list: List[str]) -> List[int]:
    ids = [CATEGORY_MAP[name] for name in recommend_list if name in CATEGORY_MAP]
    if not ids:
        ids = [0]  # ê¸°ë³¸ê°’: ê¸°íƒ€
    return ids


# ==============================
# ğŸ“¦ DTO ì •ì˜
# ==============================

@dataclass
class InstagramPostDTO:
    """ğŸ“¸ Instagram ì›ë³¸ ë°ì´í„°"""
    id: str
    caption: str
    media_type: str
    permalink: str
    media_urls: List[str]

@dataclass
class GptParsedEventDTO:
    """ğŸ§  GPT íŒŒì‹± ê²°ê³¼"""
    name: str
    start_date: str
    end_date: str
    open_time: str
    close_time: str
    address: str
    region: str
    geocoding_query: str
    caption_summary: str
    recommend: list[str]
    section: Optional[int] = None

@dataclass
class PopupEventDTO:
    """ğŸ“Œ ìµœì¢… ë³‘í•© ê²°ê³¼"""
    name: str
    start_date: str
    end_date: str
    open_time: str
    close_time: str
    address: str
    region: str
    geocoding_query: str
    insta_post_id: str
    insta_post_url: str
    caption_summary: str
    caption: str
    image_url: List[str]
    image_paths: List[str]
    media_type: str
    recommend: List[int]


# ==============================
# ğŸ§  GPT íŒŒì´í”„ë¼ì¸
# ==============================

class GptAPI:
    REQUIRED_FIELDS = ["name", "start_date", "end_date", "address", "region", "caption_summary", "recommend"]  # âœ… ì¶”ê°€
    def __init__(self, access_token, model="gpt-4o-mini"):
        self.access_token = access_token
        self.model = model
        self.endpoint = "https://api.openai.com/v1/chat/completions"
        self.session = requests.Session()
        self.session.headers.update({
            "Authorization": f"Bearer {self.access_token}",
            "Content-Type": "application/json",
        })

    # ---------- ë¬¸ìì—´ ì •ì œ ----------
    @staticmethod
    def slugify(text: str) -> str:
        if not text:
            return "no_name"
        text = text.strip()
        text = re.sub(r'\s+', '_', text)
        text = re.sub(r'[^\w\-ê°€-í£]', '', text)
        return text

    # ---------- íŒŒì¼ ì…ì¶œë ¥ ----------
    def file_open(self, filename: str) -> List[InstagramPostDTO]:
        with open(filename, "r", encoding="utf-8") as f:
            raw_data = json.load(f)

        posts: List[InstagramPostDTO] = []
        for item in raw_data:
            posts.append(
                InstagramPostDTO(
                    id=item.get("id", ""),
                    caption=item.get("caption", ""),
                    media_type=item.get("media_type", ""),
                    permalink=item.get("permalink", ""),
                    media_urls=item.get("media_urls", []),
                )
            )
        return posts

    def file_save(self, data: List[PopupEventDTO]):
        path = "gpt.json"
        json_data = [obj.__dict__ for obj in data]
        with open(path, "w", encoding="utf-8") as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {os.path.abspath(path)}")
        return os.path.abspath(path)

    # ---------- GPT í”„ë¡¬í”„íŠ¸ (ì›ë¬¸ ìœ ì§€) ----------
    def build_prompt(self, sections):
        lines = []
        for idx, cap in sections:
            lines.append(f"[section {idx}]\n{cap}")
        body = "\n\n---\n\n".join(lines)

        # âœ… ì—¬ê¸°ì„œ required_fields ë¬¸ìì—´í™”
        required_list_str = ", ".join(self.REQUIRED_FIELDS)
        categories_str = ", ".join(CATEGORY_MAP.keys())

        return f"""
        ì•„ë˜ì—ëŠ” ì—¬ëŸ¬ ê°œì˜ 'ì„¹ì…˜' í…ìŠ¤íŠ¸ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.
        ê° ì„¹ì…˜ì—ëŠ” í•˜ë‚˜ ì´ìƒì˜ íŒì—… ì´ë²¤íŠ¸ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        ê° íŒì—… ì´ë²¤íŠ¸ì— ëŒ€í•´ ë‹¤ìŒ **ì†Œë¬¸ì í‚¤**ë§Œ í¬í•¨ëœ ê°ì²´ë¥¼ ìƒì„±í•˜ê³ ,
        ëª¨ë“  ê°ì²´ë¥¼ **JSON ë°°ì—´**ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ğŸ“Œ í•„ë“œë³„ ì‘ì„± ê·œì¹™
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        - name: íŒì—… ì´ë¦„ ë˜ëŠ” í–‰ì‚¬ëª…

        - start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)

        - end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)

        - open_time: ìš´ì˜ ì‹œì‘ ì‹œê°„ (HH:MM)

        - close_time: ìš´ì˜ ì¢…ë£Œ ì‹œê°„ (HH:MM)

        - address: ë„ë¡œëª… ì£¼ì†Œ ë˜ëŠ” ê±´ë¬¼ëª…
            - âš ï¸ addressê°€ ì¶”ì¶œë˜ì§€ ì•ŠëŠ” ê²½ìš°, ì´ ì´ë²¤íŠ¸ëŠ” JSONì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

        - region: ì§€ì—­ëª… (ì˜ˆ: ì„œìš¸, ë¶€ì‚°, ë„ì¿„)
            - âš ï¸ regionì´ ëˆ„ë½ë˜ë©´ ì´ ì´ë²¤íŠ¸ëŠ” JSONì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

        - geocoding_query: addressì™€ region, nameì„ ê¸°ë°˜ìœ¼ë¡œ ì§€ì˜¤ì½”ë”© API ê²€ìƒ‰ì— ìµœì í™”ëœ ë¬¸ìì—´
            1) ì§€ì—­(region)ì„ ë°˜ë“œì‹œ ê°€ì¥ ì•ì— ë¶™ì´ì„¸ìš”. (ì˜ˆ: 'ë¶€ì‚°', 'ì„œìš¸', 'ì„±ë‚¨')
            2) address ë˜ëŠ” nameì—ì„œ ê±´ë¬¼ëª…, ê³µê°„ëª… ë“±ì˜ í•µì‹¬ ì§€ëª… ìš”ì†Œë§Œ ë¶™ì´ì„¸ìš”.
            - ì˜ˆ: "ì„±ë‚¨ í˜„ëŒ€ë°±í™”ì  íŒêµ" âœ…
            - ì˜ˆ: "ì„±ë‚¨ í˜„ëŒ€ë°±í™”ì  íŒêµ ë„ì”¨" âŒ (ë¸Œëœë“œëª… ì œê±°)
            3) ì¸µìˆ˜, ë°©í–¥, ì¡°ì‚¬ ë“± ë¶ˆí•„ìš”í•œ ë‹¨ì–´ëŠ” ì œê±°í•˜ì„¸ìš”:
            - 'B1', '1ì¸µ', '2F', 'B2F', 'ì§€í•˜ 1ì¸µ'
            - 'ì•', 'ê·¼ì²˜', 'ë§ì€í¸', 'ì˜†', 'ë’·í¸', 'ì•ìª½', 'ë’¤í¸'
            - '~ì—ì„œ', '~ì•', '~ê·¼ì²˜', '~ë§ì€í¸'
            4) ë¸Œëœë“œëª…, íŒì—… ì´ë¦„, ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„, ì œí’ˆ ì´ë¦„ ë“±ì€ ë°˜ë“œì‹œ ì œê±°í•˜ì„¸ìš”.
            - ì˜ˆ: "ì„œìš¸ ì‹ ì´Œìœ í”Œë ‰ìŠ¤ í›„ë¥´ì¸ ë°”ìŠ¤ì¼“" â†’ "ì„œìš¸ ì‹ ì´Œìœ í”Œë ‰ìŠ¤"
            - ì˜ˆ: "ì„œìš¸ í˜„ëŒ€ë°±í™”ì  ì••êµ¬ì •ë³¸ì  ê¹€ì¬ì¤‘" â†’ "ì„œìš¸ í˜„ëŒ€ë°±í™”ì  ì••êµ¬ì •ë³¸ì "
            - ì˜ˆ: "ë¶€ì‚° ì‹ ì„¸ê³„ë°±í™”ì  ìŠ¤íƒ€í•„ë“œ íŒì—…ìŠ¤í† ì–´" â†’ "ë¶€ì‚° ì‹ ì„¸ê³„ë°±í™”ì  ìŠ¤íƒ€í•„ë“œ"
            5) íŒì—…ëª…ê³¼ addressê°€ ë™ì¼í•˜ë”ë¼ë„ ë¸Œëœë“œëª…ì€ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.
            6) ë¸Œëœë“œëª…ì´ ì œê±°ëœ í›„ì—ë„ ìµœì†Œí•œ ì§€ì—­ + ê±´ë¬¼ëª…/ì§€ëª…ì€ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            7) addressê°€ ì—†ëŠ” ê²½ìš° nameì—ì„œ ì§€ëª…/ê±´ë¬¼ëª…ë§Œ ì¶”ì¶œí•˜ì„¸ìš”. ë¸Œëœë“œëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            8) ë‹¨ìˆœíˆ ì§€ì—­ëª…ë§Œ ì“°ëŠ” ê²ƒì€ ê¸ˆì§€ì…ë‹ˆë‹¤. (ì˜ˆ: "ì„±ë‚¨" âŒ)
            ë°˜ë“œì‹œ "ì„±ë‚¨ í˜„ëŒ€ë°±í™”ì  íŒêµ"ì²˜ëŸ¼ êµ¬ì²´ì ì¸ ì§€ëª…ê¹Œì§€ í¬í•¨í•˜ì„¸ìš”.
            9) ë¬¸ì¥í˜•ì´ ì•„ë‹ˆë¼ ì§§ê³  ê²€ìƒ‰ ìµœì í™”ëœ ëª…ì‚¬êµ¬ë¡œ ì‘ì„±í•˜ì„¸ìš”.

        - section: ì´ ì´ë²¤íŠ¸ê°€ ì¶”ì¶œëœ ì„¹ì…˜ ë²ˆí˜¸(ì •ìˆ˜)

        - caption_summary: "caption_summaryëŠ” ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼, ì¸ìŠ¤íƒ€ ì›ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì™„ì„±ëœ ê²Œì‹œê¸€í˜• ë¬¸ë‹¨ì…ë‹ˆë‹¤. \
            âœ¨ êµ¬ì„± ê·œì¹™:\n
            - ì „ì²´ëŠ” ì•½ 6~10ì¤„ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
            - ìƒë‹¨ì—ëŠ” íŒì—… ì´ë¦„, ìœ„ì¹˜, ì¼ì •, ìš´ì˜ì‹œê°„ì„ ê°„ê²°íˆ í‘œì‹œí•˜ì„¸ìš”.
            - í•˜ë‹¨ì—ëŠ” íŒì—…ì˜ ë¶„ìœ„ê¸°, ì „ì‹œÂ·ì²´í—˜ ë‚´ìš©, ìš´ì˜ íŠ¹ì§• ë“±ì„ ìì—°ìŠ¤ëŸ½ê²Œ 3ì¤„ ì´ìƒìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
            - ë¬¸ì¥ì€ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ, ë§í•˜ë“¯ì´ í‘œí˜„í•˜ì„¸ìš”.
            - ê°ì„±ì ì¸ í‘œí˜„ì€ í—ˆìš©í•˜ì§€ë§Œ, ê³¼ì¥ë˜ê±°ë‚˜ í™ë³´ì„± ì–´íˆ¬ëŠ” í”¼í•˜ì„¸ìš”.
            - ë¬¸ì¥ ì‚¬ì´ì—ëŠ” ì¤„ë°”ê¿ˆ(\\n)ì„ í¬í•¨í•˜ì„¸ìš”.
            ì˜ˆì‹œ:\\n
            ğŸ¥ Jam in Bread íŒì—…ìŠ¤í† ì–´ ì˜¤í”ˆ\\n
            ğŸ“ ì‹ ì„¸ê³„ë°±í™”ì  ê°•ë‚¨ì  B1\\n
            ğŸ“… 10.7(ì›”) ~ 10.13(ì¼)\\n
            ğŸ•¥ 10:30AM ~ 8:00PM\\n
            \\n
            ë”°ëœ»í•œ í–¥ì´ í¼ì§€ëŠ” ê³µê°„ì—ì„œ ì¼ê³¼ ë¹µì„ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n
            ë‹¤ì–‘í•œ ìˆ˜ì œì¼ê³¼ ë² ì´ì»¤ë¦¬ êµ¿ì¦ˆê°€ ì „ì‹œë˜ì–´ ìˆê³ , ì¼ë¶€ ìƒí’ˆì€ í˜„ì¥ êµ¬ë§¤ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n
            í•˜ë£¨ì˜ ì‹œì‘ì„ ë¶€ë“œëŸ½ê²Œ ì±„ì›Œì£¼ëŠ” ì‘ì€ íœ´ì‹ ê°™ì€ íŒì—…ì…ë‹ˆë‹¤.\\n"

        - recommend : ì•„ë˜ ëª©ë¡ ì¤‘ì—ì„œ ê´€ë ¨ëœ íŒì—… ì¹´í…Œê³ ë¦¬ë¥¼ **1ê°œ ì´ìƒ, ìµœëŒ€ 3ê°œê¹Œì§€** ì„ íƒí•˜ì—¬ ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
            - [{categories_str}]
            ğŸ“Œ **ì„ íƒ ê¸°ì¤€**:
                1) ìº¡ì…˜ ë˜ëŠ” íŒì—… ì´ë¦„ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ìš°ì„  ì„ íƒí•˜ì„¸ìš”.
                - ì˜ˆ: "ìŠ¤íƒ€ë²…ìŠ¤", "ì¹´í˜", "ì»¤í”¼", "ìŒë£Œ" â†’ "ì¹´í˜"
                - ì˜ˆ: "í•œì •íŒ ìŠ¤ë‹ˆì»¤ì¦ˆ", "ì‹ ë°œ", "ì˜·", "íŒ¨ì…˜ì‡¼" â†’ "íŒ¨ì…˜"
                - ì˜ˆ: "ë§¥ì£¼", "ìœ„ìŠ¤í‚¤", "ì¹µí…Œì¼" â†’ "ì£¼ë¥˜"
                - ì˜ˆ: "íŒì½˜", "ìƒì˜", "ì˜í™”ê´€" â†’ "ì˜í™”"
                - ì˜ˆ: "ì• ë‹ˆ", "ë§Œí™”", "ì½”ìŠ¤í”„ë ˆ" â†’ "ì• ë‹ˆë©”ì´ì…˜"
                - ì˜ˆ: "ì›¹íˆ°", "ë„¤ì´ë²„ì›¹íˆ°", "ì‘ê°€ì „" â†’ "ì›¹íˆ°"
                - ì˜ˆ: "íŒ¬ì‚¬ì¸íšŒ", "ê°€ìˆ˜", "ì•„ì´ëŒ", "íŒ¬ë¯¸íŒ…" â†’ "ì—°ì˜ˆì¸"
                - ì˜ˆ: "ì—¬í–‰", "ê´€ê´‘", "ìˆ™ì†Œ", "í•­ê³µ", "í•´ì™¸" â†’ "ì—¬í–‰"
                - ì˜ˆ: "ê°•ì•„ì§€", "ê³ ì–‘ì´", "ë°˜ë ¤ë™ë¬¼" â†’ "ë°˜ë ¤ë™ë¬¼"
                - ì˜ˆ: "ê²Œì„", "ì½˜ì†”", "PCë°©", "í”Œë ˆì´" â†’ "ê²Œì„"
                - ì˜ˆ: "ì±…", "ë¶ì¹´í˜", "ì„œì " â†’ "ì±…"
                - ì˜ˆ: "ê¸ˆìœµ", "ì€í–‰", "ì¹´ë“œ", "íˆ¬ì" â†’ "ê¸ˆìœµ"
                - ì˜ˆ: "ì—ì½”", "í™˜ê²½", "ì œë¡œì›¨ì´ìŠ¤íŠ¸" â†’ "ì¹œí™˜ê²½"
                - ì˜ˆ: "í‚¤ì¦ˆ", "ì–´ë¦°ì´", "ìœ ì•„" â†’ "í‚¤ì¦ˆ"
                - ì˜ˆ: "ì˜ë¥˜", "ê°€ë°©", "ì•…ì„¸ì„œë¦¬" â†’ "íŒ¨ì…˜"
                - ì˜ˆ: "í™”ì¥í’ˆ", "í–¥ìˆ˜", "ë©”ì´í¬ì—…" â†’ "ë·°í‹°"
                - ì˜ˆ: "ì¼€ì´í¬", "ì¿ í‚¤", "ì´ˆì½œë¦¿" â†’ "ë””ì €íŠ¸"
                - ì˜ˆ: "ì»¤í”¼", "ìŒë£Œ", "í‹°ë£¸" â†’ "ì¹´í˜"
                - ì˜ˆ: "í…Œí¬", "ìŠ¤ë§ˆíŠ¸í°", "ì „ìê¸°ê¸°" â†’ "IT"
                - ì˜ˆ: "ë¦¬ë¹™", "ì¸í…Œë¦¬ì–´", "ê°€êµ¬" â†’ "ìƒí™œìš©í’ˆ"
                - ì˜ˆ: "ìš´ë™", "ëŸ¬ë‹", "ìŠ¤í¬ì¸ ë¸Œëœë“œ" â†’ "ìŠ¤í¬ì¸ "
                - ì˜ˆ: "ì „ì‹œíšŒ", "ì•„íŠ¸", "í˜ì–´", "ì²´í—˜" â†’ "ë¬¸í™”/ì˜ˆìˆ "

                2) í‚¤ì›Œë“œê°€ ë‘ ê°€ì§€ ì´ìƒ ê´€ë ¨ë  ê²½ìš° ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥ (ìµœëŒ€ 3ê°œ).
                - ì˜ˆ: â€œë””ì €íŠ¸ ì¹´í˜â€ â†’ ["ë””ì €íŠ¸", "ì¹´í˜"]

                3) ê´€ë ¨ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì„ ê²½ìš°ì—ë§Œ "ê¸°íƒ€"ë¥¼ ì„ íƒí•˜ì„¸ìš”.
                - ë‹¨ìˆœíˆ ì•„ë¬´ í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆë‹¤ê³  í•´ì„œ ë¬´ì¡°ê±´ "ê¸°íƒ€"ë¥¼ ë„£ì§€ ë§ˆì„¸ìš”.
                - ë¸Œëœë“œëª…, ì œí’ˆêµ°, íŒì—… í…Œë§ˆë¥¼ ê·¼ê±°ë¡œ ì ê·¹ì ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.

            ğŸ“Œ **ë°˜í™˜ í˜•ì‹ ì˜ˆì‹œ**:
                - recommend: ["íŒ¨ì…˜"]
                - recommend: ["ì¹´í˜", "ë””ì €íŠ¸"]
                - recommend: ["ì¹œí™˜ê²½", "íŒ¨ì…˜", "ì¹´í˜"]
                - recommend: ["ê¸°íƒ€"]


        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â— í¬í•¨ ê¸°ì¤€
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        - ë°˜ë“œì‹œ ë‹¤ìŒ í•„ë“œë“¤ì´ ëª¨ë‘ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤:
        {required_list_str}
        - ìœ„ í•„ë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ëˆ„ë½ëœ ì´ë²¤íŠ¸ëŠ” JSONì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        â†’ ë¶ˆëª…í™•í•˜ê±°ë‚˜ ì£¼ì†Œ/ë‚ ì§œê°€ ì—†ëŠ” ì´ë²¤íŠ¸ëŠ” ì œì™¸í•˜ì„¸ìš”.

        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ğŸ“… ë‚ ì§œ ê·œì¹™
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        - '10/7~10/23'ì²˜ëŸ¼ ì›”/ì¼ë§Œ ìˆìœ¼ë©´ 2025ë…„ìœ¼ë¡œ ë³´ì™„í•˜ì„¸ìš”.
        - ê³¼ê±°ë…„ë„(2023, 2024 ë“±)ê°€ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
        - ëª¨í˜¸í•œ ë‚ ì§œëŠ” ì œì™¸í•˜ì„¸ìš”.

        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ğŸ•’ ì‹œê°„ ê·œì¹™
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        - '10:00~20:00' í˜•íƒœëŠ” open_time / close_timeìœ¼ë¡œ ë‚˜ëˆ„ì„¸ìš”.
        - ëª…ì‹œ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ë‘¡ë‹ˆë‹¤.

        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ğŸ–¼ ì´ë¯¸ì§€ ê·œì¹™
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        - ì´ë¯¸ì§€ê°€ ì—¬ëŸ¬ ì¥ì´ë©´ ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        - ë‹¨ì¼ ì´ë¯¸ì§€ë„ ë°°ì—´ë¡œ ê°ì‹¸ì„œ ë°˜í™˜í•˜ì„¸ìš”.

        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        âš ï¸ ì¶œë ¥ í˜•ì‹
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        - ë°˜ë“œì‹œ JSON ë°°ì—´([])ë§Œ. ì„¤ëª…/ì£¼ì„/ì½”ë“œë¸”ë¡ ê¸ˆì§€.

        {body}
        """


    # ---------- GPT í˜¸ì¶œ ----------
    def call_gpt(self, prompt, max_tokens=1500, retries=2):
        payload = {
            "model": self.model,
            "temperature": 0,
            "messages": [
                {"role": "system", "content": "ë„ˆëŠ” í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                {"role": "user", "content": prompt},
            ],
            "max_tokens": max_tokens
        }
        for attempt in range(retries + 1):
            try:
                resp = self.session.post(self.endpoint, json=payload, timeout=60)
                if resp.status_code == 200:
                    return resp.json()["choices"][0]["message"]["content"]
                else:
                    print(f"âš ï¸ ì‘ë‹µ ì˜¤ë¥˜: {resp.status_code}")
                time.sleep(1)
            except requests.RequestException as e:
                print(f"âš ï¸ ìš”ì²­ ì‹¤íŒ¨: {e}")
                time.sleep(1)
        raise RuntimeError("âŒ GPT ì‘ë‹µ ì‹¤íŒ¨")

    # ---------- GPT ê²°ê³¼ íŒŒì‹± ----------
    def extract_json_array(self, text) -> List[GptParsedEventDTO]:
        code_match = re.search(r"```(?:json)?\s*(\[[\s\S]*?\])\s*```", text)
        candidate = code_match.group(1) if code_match else self._greedy_bracket_slice(text)
        try:
            data = json.loads(candidate)
            return self._normalize_schema(data)
        except json.JSONDecodeError:
            return []

    def _normalize_schema(self, data) -> List[GptParsedEventDTO]:
        if not isinstance(data, list):
            return []
        parsed = []
        for obj in data:
            if "recommend" not in obj:
                print(f"âš ï¸ recommend ëˆ„ë½ â†’ {obj.get('name')}")
            recommend_list = obj.get("recommend") or ["ê¸°íƒ€"]
            parsed.append(
                GptParsedEventDTO(
                    name=(obj.get("name") or "").strip(),
                    start_date=(obj.get("start_date") or "").strip(),
                    end_date=(obj.get("end_date") or "").strip(),
                    open_time=(obj.get("open_time") or "").strip(),
                    close_time=(obj.get("close_time") or "").strip(),
                    address=(obj.get("address") or "").strip(),
                    region=(obj.get("region") or "").strip(),
                    geocoding_query=(obj.get("geocoding_query") or "").strip(),
                    caption_summary=(obj.get("caption_summary") or "").strip(),
                    recommend=recommend_list,
                    section=int(obj["section"]) if obj.get("section") is not None else None
                )
            )
        return parsed

    def _greedy_bracket_slice(self, text):
        start, end = text.find("["), text.rfind("]")
        return text[start:end + 1] if start != -1 and end != -1 else "[]"
    
    # ---------- í•„ìˆ˜ í•„ë“œ í•„í„° ----------
    def filter_required_fields(self, events: List[PopupEventDTO]) -> List[PopupEventDTO]:
        valid = []
        for e in events:
            missing = []
            for f in self.REQUIRED_FIELDS:
                value = getattr(e, f, "")
                # ë¬¸ìì—´ì¼ ê²½ìš° ê³µë°± ì²´í¬
                if isinstance(value, str) and not value.strip():
                    missing.append(f)
                # ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° ë¹„ì–´ìˆëŠ”ì§€ ì²´í¬
                elif isinstance(value, list) and len(value) == 0:
                    missing.append(f)

            if missing:
                print(f"âš ï¸ í•„ìˆ˜ í•„ë“œ ëˆ„ë½({missing}) â†’ {e.name or 'ì´ë¦„ ì—†ìŒ'} ì œì™¸")
                continue

            valid.append(e)
        return valid

    # ---------- ì›ë³¸ ë°ì´í„° ë³‘í•© ----------
    def _enrich_with_original(self, posts: List[InstagramPostDTO], extracted: List[GptParsedEventDTO], section_to_post):
        results: List[PopupEventDTO] = []
        for event in extracted:
            orig = section_to_post.get(event.section, InstagramPostDTO("", "", "", "", []))
            recommend_ids = convert_recommend_to_ids(event.recommend)  # âœ… ë¬¸ìì—´ â†’ ì •ìˆ˜ ë³€í™˜

            print("ë””ë²„ê¹…: recommend ë¬¸ìì—´:", event.recommend, "â†’ recommend IDs:", recommend_ids)
            results.append(
                PopupEventDTO(
                    name=event.name,
                    start_date=event.start_date,
                    end_date=event.end_date,
                    open_time=event.open_time,
                    close_time=event.close_time,
                    address=event.address,
                    region=event.region,
                    geocoding_query=event.geocoding_query,
                    insta_post_id=orig.id,
                    insta_post_url=orig.permalink,
                    caption_summary=event.caption_summary,
                    caption=orig.caption,
                    image_url=orig.media_urls,
                    image_paths=[],  # ë‹¤ìš´ë¡œë“œ í›„ ì±„ì›Œì§
                    media_type=orig.media_type,
                    recommend=recommend_ids   # âœ… ì—¬ê¸°ì„œ int ë°°ì—´ë¡œ ë³€í™˜ ì™„ë£Œ
                )
            )
        return results

    # ---------- ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ----------
    def download_images(self, event: PopupEventDTO, base_dir="images"):
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        name_slug = self.slugify(event.name) or "no_name"
        folder_name = f"{timestamp}_{event.insta_post_id}"
        folder_path = os.path.join(base_dir, folder_name)

        try:
            os.makedirs(folder_path, exist_ok=True)
        except Exception as e:
            print(f"âŒ í´ë” ìƒì„± ì‹¤íŒ¨ ({folder_path}): {e}")
            return

        image_paths = []
        valid_image_urls = []  # âœ… webp ì œê±° í›„ ë‹¤ì‹œ ë‹´ì„ ë¦¬ìŠ¤íŠ¸

        for idx, url in enumerate(event.image_url, start=1):
            try:
                if not url or not url.startswith("http"):
                    print(f"âš ï¸ ì˜ëª»ëœ URL â†’ ìŠ¤í‚µ: {url}")
                    continue

                parsed = urlparse(url)
                ext = os.path.splitext(parsed.path)[1].lower().split("?")[0]

                # ğŸš« webp ì œì™¸ â€” ì•„ì˜ˆ URL ë¦¬ìŠ¤íŠ¸ì—ì„œë„ ì œê±°
                if ext == ".webp":
                    print(f"ğŸš« webp íŒŒì¼ ìŠ¤í‚µ ë° URL ì œê±°: {url}")
                    continue

                if ext in ("", ".heic"):
                    ext = ".jpg"

                filename = f"{name_slug}_{idx}{ext}"
                filepath = os.path.join(folder_path, filename)

                resp = requests.get(url, timeout=20)
                if resp.status_code != 200:
                    print(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (status={resp.status_code}): {url}")
                    continue

                content_type = resp.headers.get("Content-Type", "").lower()
                if not content_type.startswith("image/"):
                    print(f"âš ï¸ ì´ë¯¸ì§€ ì•„ë‹˜ (Content-Type={content_type}): {url}")
                    continue

                with open(filepath, "wb") as f:
                    f.write(resp.content)

                image_paths.append(os.path.abspath(filepath))
                valid_image_urls.append(url)  # âœ… ì‹¤ì œë¡œ ì„±ê³µí•œ URLë§Œ ìœ ì§€
                print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {filepath}")

            except Exception as e:
                print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({url}): {e}")

        event.image_paths = image_paths
        event.image_url = valid_image_urls  # âœ… webp ì œê±° ë°˜ì˜



    # ---------- ì „ì²´ íŒŒì´í”„ë¼ì¸ ----------
    def process_file(self, filename, batch_size=10, download=False):
        posts = self.file_open(filename)
        sections = []
        section_to_post = {}
        for idx, post in enumerate(posts):
            if post.caption:
                sections.append((idx, post.caption))
                section_to_post[idx] = post

        if not sections:
            print("âš ï¸ ìº¡ì…˜ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        all_extracted: List[GptParsedEventDTO] = []
        for i in range(0, len(sections), batch_size):
            chunk = sections[i:i + batch_size]
            prompt = self.build_prompt(chunk)
            try:
                resp_text = self.call_gpt(prompt)
                # print("==== GPT RAW RESPONSE ====")
                # print(resp_text)
                extracted = self.extract_json_array(resp_text)
                all_extracted.extend(extracted)
            except Exception as e:
                print(f"âš ï¸ GPT ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        results = self._enrich_with_original(posts, all_extracted, section_to_post)

        if download:
            for event in results:
                self.download_images(event)

        # âœ… í•„ìˆ˜ í•„ë“œ í•„í„°ë§ ì¶”ê°€
        before_len = len(results)
        results = self.filter_required_fields(results)
        after_len = len(results)
        print(f"ğŸ“Œ í•„ìˆ˜ í•„ë“œ í•„í„°ë§: {before_len - after_len}ê±´ ì œì™¸ë¨")

        # ğŸ§¹ ì´ë¯¸ì§€ ì—†ëŠ” íŒì—… ì œê±°
        before_len = len(results)
        results = [event for event in results if len(event.image_url) > 0 or len(event.image_paths) > 0]
        after_len = len(results)

        print(f"ğŸ§¾ ì´ {before_len}ê±´ ì¤‘ {before_len - after_len}ê±´ì€ ì´ë¯¸ì§€ ì—†ìŒìœ¼ë¡œ ì œì™¸ë¨")

        return results


    # ---------- ì‹¤í–‰ ----------
    @staticmethod
    def play(download=False):
        load_dotenv()
        token = os.getenv("GPT_ACCESS_TOKEN")
        if not token:
            print("âŒ í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½: GPT_ACCESS_TOKEN")
            return
        api = GptAPI(token)
        results = api.process_file("popup.json", batch_size=10, download=download)
        api.file_save(results)
        print()


# ==============================
# ğŸ ì‹¤í–‰
# ==============================
if __name__ == "__main__":
    GptAPI.play(download=True)
